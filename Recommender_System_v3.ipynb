{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas\n",
        "! pip install numpy\n",
        "! pip install scikit-learn\n",
        "! pip install matplotlib\n",
        "! pip install joblib\n",
        "! pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNLBumsrB1uH",
        "outputId": "8a746a44-d63e-4d24-d470-5e4cc0212434"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas numpy scikit-learn joblib streamlit cloudflared\n"
      ],
      "metadata": {
        "id": "zpiZjyDfHOAr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/smart_recommender.py\n",
        "import os, math, random\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "SEED=42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "def build_synth(n_users=600,n_items=350,minr=10,maxr=25):\n",
        "    users=[f\"U{u}\" for u in range(1,n_users+1)]\n",
        "    items=[f\"P{i}\" for i in range(1,n_items+1)]\n",
        "    cats=['Electronics','Books','Home','Toys','Beauty','Sports','Clothing','Grocery']\n",
        "    rows=[]\n",
        "    for u in users:\n",
        "        k=np.random.randint(minr,maxr+1)\n",
        "        rated=np.random.choice(items,size=k,replace=False)\n",
        "        for it in rated:\n",
        "            r=np.clip(np.random.normal(3.6,1.0),1,5)\n",
        "            r=round(r*2)/2.0\n",
        "            rows.append((u,it,r))\n",
        "    ratings=pd.DataFrame(rows,columns=['userId','productId','rating'])\n",
        "    kw={'Electronics':['battery','wireless','bluetooth','USB','portable','charger'],\n",
        "        'Books':['story','novel','guide','history','author','learn'],\n",
        "        'Home':['kitchen','durable','design','compact','decor','clean'],\n",
        "        'Toys':['kids','fun','safe','interactive','educational','colorful'],\n",
        "        'Beauty':['gentle','skin','organic','scent','serum','moisturizer'],\n",
        "        'Sports':['fitness','outdoor','durable','training','performance','comfort'],\n",
        "        'Clothing':['fabric','comfortable','casual','size','style','soft'],\n",
        "        'Grocery':['fresh','organic','snack','ingredients','package','tasty']}\n",
        "    metas=[]\n",
        "    for i,p in enumerate(items,1):\n",
        "        c=random.choice(cats); title=f\"{c} Product {i}\"\n",
        "        desc=\" \".join(np.random.choice(kw[c],size=6,replace=True))\n",
        "        metas.append({'productId':p,'title':title,'category':c,'description':f\"{title}. {desc}. High quality and good value.\"})\n",
        "    products=pd.DataFrame(metas)\n",
        "    return ratings,products\n",
        "\n",
        "def preprocess(df):\n",
        "    df=df.drop_duplicates().dropna(subset=['userId','productId','rating']).reset_index(drop=True)\n",
        "    df['userId']=df['userId'].astype(str); df['productId']=df['productId'].astype(str)\n",
        "    df['rating']=pd.to_numeric(df['rating'],errors='coerce').astype(float)\n",
        "    return df\n",
        "\n",
        "def add_implicit(df):\n",
        "    mult=np.random.uniform(0.8,1.4,size=len(df))\n",
        "    df=df.copy()\n",
        "    df['implicit_score']=(df['rating']/5.0)*mult\n",
        "    return df\n",
        "\n",
        "def train_cf(train_df,n_components=30):\n",
        "    users=sorted(train_df['userId'].unique())\n",
        "    items=sorted(train_df['productId'].unique())\n",
        "    pivot=train_df.pivot_table(index='userId',columns='productId',values='rating').reindex(index=users,columns=items)\n",
        "    filled=pivot.copy()\n",
        "    umean=pivot.mean(axis=1); gmean=train_df['rating'].mean()\n",
        "    for u in users:\n",
        "        filled.loc[u]=filled.loc[u].fillna(umean.loc[u] if not np.isnan(umean.loc[u]) else gmean)\n",
        "    svd=TruncatedSVD(n_components=n_components,random_state=SEED)\n",
        "    U=svd.fit_transform(filled.values); V=svd.components_.T\n",
        "    pred=np.dot(U,V.T)\n",
        "    pred_df=pd.DataFrame(pred,index=users,columns=items)\n",
        "    return svd,pred_df,filled\n",
        "\n",
        "def train_cbf(products,max_features=2000):\n",
        "    vec=TfidfVectorizer(max_features=max_features,stop_words='english')\n",
        "    X=vec.fit_transform(products['description'].fillna(products['title'].fillna('')))\n",
        "    return vec,X\n",
        "\n",
        "def evaluate_rmse(pred_df,test_df):\n",
        "    y_true=[]; y_pred=[]\n",
        "    for _,r in test_df.iterrows():\n",
        "        u,p,rt=r['userId'],r['productId'],r['rating']\n",
        "        if (u in pred_df.index) and (p in pred_df.columns):\n",
        "            y_true.append(rt); y_pred.append(pred_df.loc[u,p])\n",
        "    return mean_squared_error(y_true,y_pred,squared=False) if y_true else None\n",
        "\n",
        "def precision_at_k(pred_df,train_df,test_df,k=5,thr=4.0):\n",
        "    users=test_df['userId'].unique(); precs=[]\n",
        "    for u in users:\n",
        "        if u not in pred_df.index: continue\n",
        "        train_items=set(train_df[train_df['userId']==u]['productId'])\n",
        "        cand=[i for i in pred_df.columns if i not in train_items]\n",
        "        if not cand: continue\n",
        "        top=sorted([(i,pred_df.loc[u,i]) for i in cand],key=lambda x:x[1],reverse=True)[:k]\n",
        "        top_ids=[i for i,_ in top]\n",
        "        relevant=set(test_df[(test_df['userId']==u)&(test_df['rating']>=thr)]['productId'])\n",
        "        if not top_ids: continue\n",
        "        prec=len([i for i in top_ids if i in relevant])/len(top_ids)\n",
        "        precs.append(prec)\n",
        "    return float(np.mean(precs)) if precs else 0.0\n",
        "\n",
        "def train_and_save():\n",
        "    ratings,products=build_synth()\n",
        "    ratings=preprocess(ratings)\n",
        "    ratings=add_implicit(ratings)\n",
        "    train_df,test_df=train_test_split(ratings,test_size=0.2,random_state=SEED)\n",
        "    svd,pred_df,filled=train_cf(train_df,30)\n",
        "    vec,X=train_cbf(products)\n",
        "    rmse=evaluate_rmse(pred_df,test_df)\n",
        "    p5=precision_at_k(pred_df,train_df,test_df,5,4.0)\n",
        "    print(f\"RMSE: {rmse:.4f} | Precision@5: {p5:.4f}\")\n",
        "    out=\"/content/recommender_app/models\"; os.makedirs(out,exist_ok=True)\n",
        "    joblib.dump(pred_df, f\"{out}/pred_matrix_df.pkl\")\n",
        "    joblib.dump(svd, f\"{out}/truncated_svd.pkl\")\n",
        "    joblib.dump(vec, f\"{out}/tfidf_vectorizer.pkl\")\n",
        "    joblib.dump(X, f\"{out}/tfidf_matrix.pkl\")\n",
        "    products.to_pickle(f\"{out}/products_df.pkl\")\n",
        "    train_df.to_pickle(f\"{out}/train_ratings_df.pkl\")\n",
        "    print(\"Artifacts saved to\", out)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_and_save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XALtgPzMH53H",
        "outputId": "c332ffe9-322a-4c6c-eeba-027159b35a46"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/smart_recommender.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python - <<'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"/content/smart_recommender.py\")\n",
        "if not p.exists():\n",
        "    print(\"ERROR: /content/smart_recommender.py not found. Make sure file path is correct.\")\n",
        "    raise SystemExit(1)\n",
        "\n",
        "text = p.read_text()\n",
        "\n",
        "old_snip = \"\"\"\n",
        "def evaluate_rmse(pred_df,test_df):\n",
        "    y_true=[]; y_pred=[]\n",
        "    for _,r in test_df.iterrows():\n",
        "        u,p,rt=r['userId'],r['productId'],r['rating']\n",
        "        if (u in pred_df.index) and (p in pred_df.columns):\n",
        "            y_true.append(rt); y_pred.append(pred_df.loc[u,p])\n",
        "    return mean_squared_error(y_true,y_pred,squared=False) if y_true else None\n",
        "\"\"\"\n",
        "\n",
        "new_snip = \"\"\"\n",
        "import numpy as np\n",
        "def evaluate_rmse(pred_df,test_df):\n",
        "    # compute RMSE without relying on sklearn's 'squared' parameter for compatibility\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for _,r in test_df.iterrows():\n",
        "        u = r['userId']; p = r['productId']; rt = r['rating']\n",
        "        if (u in pred_df.index) and (p in pred_df.columns):\n",
        "            y_true.append(rt)\n",
        "            y_pred.append(pred_df.loc[u, p])\n",
        "    if len(y_true) == 0:\n",
        "        return None\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    return float(np.sqrt(mse))\n",
        "\"\"\"\n",
        "\n",
        "if old_snip in text:\n",
        "    text = text.replace(old_snip, new_snip)\n",
        "    p.write_text(text)\n",
        "    print(\"Patched evaluate_rmse in /content/smart_recommender.py\")\n",
        "else:\n",
        "    # fallback: try to insert function by searching for function name\n",
        "    import re\n",
        "    if re.search(r\"def evaluate_rmse\\(\", text):\n",
        "        text = re.sub(r\"def evaluate_rmse\\\\([\\\\s\\\\S]*?\\\\)\\\\n\\\\s*return[\\\\s\\\\S]*?\\\\n\", new_snip + \"\\n\", text, flags=re.MULTILINE)\n",
        "        p.write_text(text)\n",
        "        print(\"Replaced evaluate_rmse via regex in /content/smart_recommender.py\")\n",
        "    else:\n",
        "        print(\"Could not find evaluate_rmse function. Please open the file and replace the function with the new version manually.\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVfjYTmsVESu",
        "outputId": "722422c6-c934-44c7-c7d8-7f3ece5900a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched evaluate_rmse in /content/smart_recommender.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/smart_recommender.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Jnsmb9IWLV",
        "outputId": "1045799f-fa0f-4a30-ffe0-abeb177b2423"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9577 | Precision@5: 0.0045\n",
            "Artifacts saved to /content/recommender_app/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/streamlit_recommender_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "@st.cache_resource\n",
        "def load_artifacts():\n",
        "    pred_matrix_df = joblib.load(\"/content/recommender_app/models/pred_matrix_df.pkl\")\n",
        "    svd = joblib.load(\"/content/recommender_app/models/truncated_svd.pkl\")\n",
        "    tfidf_vectorizer = joblib.load(\"/content/recommender_app/models/tfidf_vectorizer.pkl\")\n",
        "    tfidf_matrix = joblib.load(\"/content/recommender_app/models/tfidf_matrix.pkl\")\n",
        "    products_df = pd.read_pickle(\"/content/recommender_app/models/products_df.pkl\")\n",
        "    ratings_df = pd.read_pickle(\"/content/recommender_app/models/train_ratings_df.pkl\")\n",
        "    return pred_matrix_df, tfidf_vectorizer, tfidf_matrix, products_df, ratings_df\n",
        "\n",
        "pred_matrix_df, tfidf_vectorizer, tfidf_matrix, products_df, ratings_df = load_artifacts()\n",
        "\n",
        "CATEGORY_TO_IMAGE = {\n",
        "    \"Electronics\": \"https://source.unsplash.com/800x520/?electronics,gadgets\",\n",
        "    \"Books\": \"https://source.unsplash.com/800x520/?books,reading\",\n",
        "    \"Home\": \"https://source.unsplash.com/800x520/?home,interior\",\n",
        "    \"Toys\": \"https://source.unsplash.com/800x520/?toys,kids\",\n",
        "    \"Beauty\": \"https://source.unsplash.com/800x520/?beauty,cosmetics\",\n",
        "    \"Sports\": \"https://source.unsplash.com/800x520/?sports,fitness\",\n",
        "    \"Clothing\": \"https://source.unsplash.com/800x520/?clothing,fashion\",\n",
        "    \"Grocery\": \"https://source.unsplash.com/800x520/?grocery,food\",\n",
        "}\n",
        "def img_for(cat): return CATEGORY_TO_IMAGE.get(cat, \"https://source.unsplash.com/800x520/?product\")\n",
        "\n",
        "PROD_TO_IDX = {pid: idx for idx, pid in enumerate(products_df[\"productId\"])}\n",
        "POPULAR_ORDER = list(ratings_df[\"productId\"].value_counts().index)\n",
        "\n",
        "def dynamic_weights(num_ratings, min_r=5, max_r=40):\n",
        "    if num_ratings <= min_r: a_cf = 0.25\n",
        "    else: a_cf = 0.25 + 0.65 * min(num_ratings - min_r, max_r - min_r) / (max_r - min_r)\n",
        "    return a_cf, 1.0 - a_cf\n",
        "\n",
        "def build_explanations(user_id, pid, cf_raw, cbf_score):\n",
        "    reasons=[]\n",
        "    cf_norm=(cf_raw-1)/4 if cf_raw is not None else 0.0\n",
        "    if cf_norm>0.5: reasons.append(\"Users with tastes like yours rated this highly.\")\n",
        "    liked = ratings_df[(ratings_df.userId==user_id) & (ratings_df.rating>=4.0)]['productId'].tolist()\n",
        "    if cbf_score>0.12 and liked:\n",
        "        liked_idxs=[PROD_TO_IDX[l] for l in liked if l in PROD_TO_IDX]\n",
        "        if pid in PROD_TO_IDX and liked_idxs:\n",
        "            p_idx=PROD_TO_IDX[pid]\n",
        "            sims=cosine_similarity(tfidf_matrix[p_idx], tfidf_matrix[liked_idxs]).flatten()\n",
        "            best_idx=liked_idxs[int(np.argmax(sims))]\n",
        "            best_title=products_df.iloc[best_idx]['title']\n",
        "            reasons.append(f\"Similar to what you liked: '{best_title}'.\")\n",
        "        else:\n",
        "            reasons.append(\"Shares features with items you liked.\")\n",
        "    if pid in POPULAR_ORDER:\n",
        "        rnk=POPULAR_ORDER.index(pid)+1\n",
        "        if rnk<=20: reasons.append(f\"Popular choice (top {rnk} most-rated).\")\n",
        "    if not reasons: reasons.append(\"Recommended by hybrid model signals.\")\n",
        "    return reasons\n",
        "\n",
        "def recommend(user_id, n=5):\n",
        "    all_p = products_df['productId'].tolist()\n",
        "    seen = ratings_df[ratings_df.userId==user_id]['productId'].tolist()\n",
        "    cand = [p for p in all_p if p not in seen]\n",
        "    num_r = len(ratings_df[ratings_df.userId==user_id])\n",
        "    a_cf,a_cbf = dynamic_weights(num_r)\n",
        "    rows=[]\n",
        "    for p in cand:\n",
        "        cf_raw = float(pred_matrix_df.loc[user_id,p]) if (user_id in pred_matrix_df.index and p in pred_matrix_df.columns) else 0.0\n",
        "        cf_norm=(cf_raw-1)/4\n",
        "        liked = ratings_df[(ratings_df.userId==user_id) & (ratings_df.rating>=4.0)]['productId'].tolist()\n",
        "        if liked and (p in PROD_TO_IDX):\n",
        "            p_idx=PROD_TO_IDX[p]\n",
        "            liked_idxs=[PROD_TO_IDX[l] for l in liked if l in PROD_TO_IDX]\n",
        "            cbf_sim = float(cosine_similarity(tfidf_matrix[p_idx], tfidf_matrix[liked_idxs]).flatten().mean()) if liked_idxs else 0.0\n",
        "        else:\n",
        "            cbf_sim=0.0\n",
        "        score = a_cf*cf_norm + a_cbf*cbf_sim\n",
        "        meta = products_df.loc[products_df.productId==p].iloc[0]\n",
        "        rows.append({\n",
        "            \"productId\": p,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"category\": meta[\"category\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"hybrid_score\": float(score),\n",
        "            \"cf_raw\": float(cf_raw),\n",
        "            \"cbf_sim\": float(cbf_sim),\n",
        "            \"reasons\": build_explanations(user_id,p,cf_raw,cbf_sim),\n",
        "            \"image_url\": img_for(meta[\"category\"]),\n",
        "        })\n",
        "    out = pd.DataFrame(rows).sort_values(\"hybrid_score\", ascending=False).head(n).reset_index(drop=True)\n",
        "    return out, a_cf, a_cbf\n",
        "\n",
        "st.title(\"🛒 Smart Product Recommender Dashboard (Colab)\")\n",
        "st.caption(\"Weighted Hybrid: Collaborative + Content-Based with explanations\")\n",
        "\n",
        "users = sorted(ratings_df['userId'].unique())\n",
        "user = st.selectbox(\"Select User ID\", users)\n",
        "n = st.slider(\"Number of recommendations\", 3, 10, 5)\n",
        "\n",
        "if st.button(\"🔍 Get Recommendations\"):\n",
        "    df, a_cf, a_cbf = recommend(user, n)\n",
        "    st.subheader(f\"🎯 Recommendations for {user}\")\n",
        "    st.caption(f\"Weights → CF: {a_cf:.2f} | CBF: {a_cbf:.2f}\")\n",
        "    for _, row in df.iterrows():\n",
        "        st.image(row[\"image_url\"])\n",
        "        st.markdown(f\"### {row['title']}\")\n",
        "        st.markdown(f\"*Category:* {row['category']}\")\n",
        "        st.markdown(f\"**Hybrid Score:** {row['hybrid_score']:.3f}  |  **CF(raw):** {row['cf_raw']:.3f}  |  **CBF(sim):** {row['cbf_sim']:.3f}\")\n",
        "        st.markdown(\"**Why this?**\")\n",
        "        for reason in row[\"reasons\"]:\n",
        "            st.markdown(f\"- {reason}\")\n",
        "        st.caption(row[\"description\"][:220] + (\"...\" if len(row[\"description\"])>220 else \"\"))\n",
        "        st.divider()\n",
        "\n",
        "st.sidebar.header(\"📈 How it works\")\n",
        "st.sidebar.markdown(\"- **CF** learns from similar users' ratings.\\n- **CBF** compares product text (TF-IDF).\\n- **Weights** adapt to how active the user is (cold-start aware).\\n- Unsplash placeholders used for images; replace with your own if available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6WcFixSIgja",
        "outputId": "64e8d9a5-4140-4406-b43d-6c19778d1527"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/streamlit_recommender_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Streamlit in background\n",
        "!streamlit run /content/streamlit_recommender_app.py &>/content/streamlit.log &\n",
        "\n",
        "# Expose via Cloudflare tunnel (prints a public URL)\n",
        "!nohup cloudflared tunnel --url http://localhost:8501 --no-autoupdate > /content/cf.log 2>&1 & sleep 3; grep -o 'https://.*trycloudflare.com' -m 1 /content/cf.log\n"
      ],
      "metadata": {
        "id": "v6yCIKuFIm02"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Reinstall/ensure deps\n",
        "!pip -q install cloudflared streamlit >/dev/null\n",
        "\n",
        "# 2) Kill any stale processes\n",
        "!pkill -f streamlit || true\n",
        "!pkill -f cloudflared || true\n",
        "\n",
        "# 3) Start Streamlit (headless) in background\n",
        "!streamlit run /content/streamlit_recommender_app.py --server.port 8501 --server.headless true &>/content/streamlit.log &\n",
        "\n",
        "# 4) Start Cloudflare tunnel in background\n",
        "!nohup cloudflared tunnel --url http://localhost:8501 --no-autoupdate > /content/cf.log 2>&1 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBVNrZq2Im2C",
        "outputId": "ca225697-3906-469e-e962-a6d810a35d9a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is Streamlit actually running?\n",
        "!ps -ef | grep streamlit | grep -v grep\n",
        "\n",
        "# Any traceback in Streamlit logs?\n",
        "!sed -n '1,200p' /content/streamlit.log\n",
        "\n",
        "# Any errors in cloudflared?\n",
        "!sed -n '1,200p' /content/cf.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vyl-iwEtJzm2",
        "outputId": "512f96d2-c05b-4d95-882a-bdf5e420afcd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        6405       1 27 12:16 ?        00:00:01 /usr/bin/python3 /usr/local/bin/streamlit run /content/streamlit_recommender_app.py --server.port 8501 --server.headless true\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.80.34.3:8501\n",
            "\n",
            "2025-10-12T12:16:08Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2025-10-12T12:16:08Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "2025-10-12T12:16:11Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-10-12T12:16:11Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "2025-10-12T12:16:11Z INF |  https://sixth-watches-micro-cats.trycloudflare.com                                        |\n",
            "2025-10-12T12:16:11Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-10-12T12:16:11Z INF Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "2025-10-12T12:16:11Z INF Version 2025.9.1 (Checksum 3dc1dc4252eae3c691861f926e2b8640063a2ce534b07b7a3f4ec2de439ecfe3)\n",
            "2025-10-12T12:16:11Z INF GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "2025-10-12T12:16:11Z INF Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "2025-10-12T12:16:11Z INF Generated Connector ID: 55f103a4-040b-49bc-85e9-ea52e2c30f0e\n",
            "2025-10-12T12:16:11Z INF Initial protocol quic\n",
            "2025-10-12T12:16:11Z INF ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "2025-10-12T12:16:11Z INF ICMP proxy will use :: as source for IPv6\n",
            "2025-10-12T12:16:11Z ERR Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable originCertPath=\n",
            "2025-10-12T12:16:11Z INF ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "2025-10-12T12:16:11Z INF ICMP proxy will use :: as source for IPv6\n",
            "2025-10-12T12:16:11Z INF Starting metrics server on 127.0.0.1:20241/metrics\n",
            "2025-10-12T12:16:11Z INF Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] connIndex=0 event=0 ip=198.41.192.167\n",
            "2025/10/12 12:16:11 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "2025-10-12T12:16:11Z INF Registered tunnel connection connIndex=0 connection=2cf8a05f-b9b2-4e4b-aa2b-4150bc2be78a event=0 ip=198.41.192.167 location=hkg09 protocol=quic\n"
          ]
        }
      ]
    }
  ]
}